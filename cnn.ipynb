{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from conv import Conv3x3\n",
    "from maxpool import MaxPool2\n",
    "from softmax import Softmax\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the path to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fdata1\n"
     ]
    }
   ],
   "source": [
    "data_path = \"Fdata1\"\n",
    "print (data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 0\n",
    "class_names = []\n",
    "img_size = (128, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize empty lists for images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in os.listdir(data_path):\n",
    "    class_dir = os.path.join(data_path, class_name)\n",
    "    if os.path.isdir(class_dir):\n",
    "        class_images = os.listdir(class_dir)\n",
    "        num_images += len(class_images)\n",
    "        class_names.append(class_name)\n",
    "        \n",
    "        # Iterate over image files in class directory\n",
    "        for image_name in class_images:\n",
    "            image_path = os.path.join(class_dir, image_name)\n",
    "            \n",
    "            # Load image and append to images list\n",
    "            image = Image.open(image_path)\n",
    "            image = image.resize(img_size)\n",
    "            \n",
    "            # Convert to grayscale\n",
    "            gray_image = image.convert('L')\n",
    "            image_data = np.array(gray_image)\n",
    "            images.append(image_data)\n",
    "            \n",
    "            # Append label to labels list\n",
    "            labels.append(class_names.index(class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n"
     ]
    }
   ],
   "source": [
    "print(images[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 3 classes: ['Akshay Kumar', 'Amitabh Bachchan', 'Urvish']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {num_images} images belonging to {num_classes} classes: {class_names}\")\n",
    "# Load the data and split it into training and validation sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = Conv3x3(8)                  # 28x28x1 -> 26x26x8\n",
    "pool = MaxPool2()                  # 26x26x8 -> 13x13x8\n",
    "softmax = Softmax(63 * 63 * 8, num_classes ) # 13x13x8 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(image, label):\n",
    "  '''\n",
    "  Completes a forward pass of the CNN and calculates the accuracy and\n",
    "  cross-entropy loss.\n",
    "  - image is a 2d numpy array\n",
    "  - label is a digit\n",
    "  '''\n",
    "  # We transform the image from [0, 255] to [-0.5, 0.5] to make it easier\n",
    "  # to work with. This is standard practice.\n",
    "  out = conv.forward((image / 255) - 0.5)\n",
    "  out = pool.forward(out)\n",
    "  out = softmax.forward(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate cross-entropy loss and accuracy. np.log() is the natural log.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(\u001b[43mout\u001b[49m[label])\n\u001b[0;32m      3\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(out) \u001b[38;5;241m==\u001b[39m label \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "  # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
    "  loss = -np.log(out[label])\n",
    "  acc = 1 if np.argmax(out) == label else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  return out, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(im, label, lr=.005):\n",
    "  '''\n",
    "  Completes a full training step on the given image and label.\n",
    "  Returns the cross-entropy loss and accuracy.\n",
    "  - image is a 2d numpy array\n",
    "  - label is a digit\n",
    "  - lr is the learning rate\n",
    "  '''\n",
    "  # Forward\n",
    "  out, loss, acc = forward(im, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate initial gradient\u001b[39;00m\n\u001b[0;32m      2\u001b[0m gradient \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m gradient[label] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[43mout\u001b[49m[label]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "  # Calculate initial gradient\n",
    "  gradient = np.zeros(10)\n",
    "  gradient[label] = -1 / out[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Backprop\n",
    "  gradient = softmax.backprop(gradient, lr)\n",
    "  gradient = pool.backprop(gradient)\n",
    "  gradient = conv.backprop(gradient, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MNIST CNN initialized!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the CNN for 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "  print('--- Epoch %d ---' % (epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Shuffle the training data\n",
    "  permutation = np.random.permutation(len(train_images))\n",
    "  train_images = train_images[permutation]\n",
    "  train_labels = train_labels[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Train!\n",
    "  loss = 0\n",
    "  num_correct = 0\n",
    "  for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
    "    if i % 100 == 99:\n",
    "      print(\n",
    "        '[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %\n",
    "        (i + 1, loss / 100, num_correct)\n",
    "      )\n",
    "      loss = 0\n",
    "      num_correct = 0\n",
    "    l, acc = train(im, label)\n",
    "    loss += l\n",
    "    num_correct += acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Calculate and store loss for the current epoch\n",
    "    train_loss = loss / len(train_images)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Calculate and store test loss for the current epoch\n",
    "    test_loss = 0\n",
    "    for im, label in zip(test_images, test_labels):\n",
    "        _, l, _ = forward(im, label)\n",
    "        test_loss += l\n",
    "    test_loss /= len(test_images)\n",
    "    test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n--- Testing the CNN ---')\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "for im, label in zip(test_images, test_labels):\n",
    "  _, l, acc = forward(im, label)\n",
    "  loss += l\n",
    "  num_correct += acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tests = len(test_images)\n",
    "print('Test Loss:', loss / num_tests)\n",
    "print('Test Accuracy:', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss vs epoch graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1, len(train_losses)+1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, test_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path):\n",
    "  # Load the image you want to predict\n",
    "  \n",
    "  image = Image.open(image_path)\n",
    "  plt.imshow(image)\n",
    "  plt.show()\n",
    "  image = image.resize((128, 128))\n",
    "  gray_image = image.convert('L')\n",
    "  image_data = np.array(gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Forward pass through the CNN to get prediction\n",
    "  out = conv.forward((image_data / 255) - 0.5)\n",
    "  out = pool.forward(out)\n",
    "  out = softmax.forward(out)\n",
    "  prediction = np.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Print the predicted class\n",
    "  # class_names = [\"class1\", \"class2\", \"class3\", ...] # replace with your own class names\n",
    "  print(\"Predicted class:\", class_names[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(\"FData1\\Alia Bhatt\\Alia Bhatt_4.jpg\")\n",
    "predict_image(\"FData1\\Alia Bhatt\\Alia Bhatt_7.jpg\")\n",
    "predict_image(\"FData1\\Akshay Kumar\\Akshay Kumar_4.jpg\")\n",
    "predict_image(\"FData1\\Akshay Kumar\\Akshay Kumar_4.jpg\")\n",
    "predict_image(\"FData1\\Alexandra Daddario\\Alexandra Daddario_4.jpg\")\n",
    "predict_image(\"FData1\\Amitabh Bachchan\\Amitabh Bachchan_4.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "venv311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
